# Phase 2b: User Persona Reactions

> DraftCrane Source/Research UX Design Review
> Persona-based evaluation of three mental model proposals
> Date: 2026-02-19

---

## Option A: "Polished Library"

### Diane Mercer's Reactions

**1. "If I opened DraftCrane and saw this, what would I think it does?"**

Okay, so I've got my chapters on the left -- that makes sense, that's like a table of contents. The writing area in the middle, fine, that's my document. And then there's this panel on the right that says "Sources" with a search box and an "Add" button.

My first thought: "Sources? Like a bibliography?" I haven't written a bibliography since grad school. I'd wonder if this is something I'm supposed to fill in for proper citations. It takes me a few seconds to realize these are my Google Docs -- my workshop notes, my interview transcripts, the stuff I'm writing *from*. The word "Sources" doesn't connect to how I think about my files. I think of them as "my notes" or "my stuff." I'd probably figure it out after 15 seconds, but that initial flash of "is this for academics?" would make me feel like maybe this tool isn't for someone like me.

The layout itself, though -- three columns, everything visible at once -- that I understand immediately. It looks like a workspace. Left is navigation, middle is where I write, right is... reference material, I guess. That part is intuitive. I've used enough apps to get the three-column thing.

**2. "Can I figure out how to find something in my research materials without instructions?"**

I see the search box at the top of the right panel. Okay. I'd tap it and type "managers who receive coaching" or maybe just "coaching stats." If my docs are already in that panel, I'd expect the search to filter the list down to relevant files.

Here's where I'd get stuck: Does the search look *inside* the documents? Or does it just match file names? Because my Google Doc titles are useless -- things like "Workshop Notes March 2024" and "Client Debrief - Consolidated." The stat I'm looking for could be in any of them. If the search only matches titles, I'm stuck scrolling through every document one by one, opening each, reading, closing, opening the next. That's basically what I do now in Google Drive.

If the search looks inside the documents and shows me where the match is -- *that* would be the moment I'd say "oh, this is actually useful." But the design doesn't make it obvious which kind of search this is. I'd try it and see. If it only matches titles, I'd be disappointed but not surprised. That's how most things work.

**3. "If I'm writing Chapter 4 and need to check a fact from an old workshop doc, what do I do?"**

I'm in the zone. I just wrote a paragraph about psychological safety and I want to verify that stat -- was it 67% or 76% of teams that reported improvement? I glance right. The sources panel is already there. Good, I don't have to go find it.

I scan the file names. "Workshop Notes March 2024" -- maybe that one? I tap it. The list disappears and shows me the document content with a "Back" button at the top. Now I'm scrolling through the whole document looking for that stat.

This is the pain point: I'm reading through a 3,000-word document looking for one number. There's no way to search within this document view. I'm just scrolling and scanning. Meanwhile, my chapter has disappeared because the source content replaced the list, and on my iPad in portrait mode, the source viewer takes up the whole screen. I can't see what I was writing. I'm going to lose my train of thought.

I'd find the stat eventually -- or maybe I wouldn't, maybe it's in a different document, and now I need to tap "Back," pick a different file, and start the scroll-and-scan again. By the time I find it, the paragraph I was writing has gone cold. This is better than switching between Safari tabs, but honestly? Not by a lot.

**4. "Does this feel like one more thing to learn, or like it's helping me?"**

It feels... neutral. Like, it's not *complicated*. I can see what everything does. There's no jargon I don't understand (except "Sources," which I'd get over). It's clean. I wouldn't need anyone to explain it to me.

But it also doesn't feel like it's *doing* anything for me. It's a file browser next to my writing. I already have a file browser -- it's called Google Drive. The difference is that this one is right there instead of in another tab. Is that enough to change my workflow? Honestly, maybe. Not having to switch tabs is genuinely helpful. But I was hoping for more. When I heard "writing tool with AI," I imagined something that would help me *find* things, not just show me a list of files.

It reduces one annoyance (tab switching) without solving the real problem (I can't find anything in my own notes).

**5. "What would make me go back to copy-pasting between Google Docs and ChatGPT?"**

If I have to manually scroll through every document to find what I'm looking for, I'll go back to ChatGPT within a week. ChatGPT is messy -- I have to paste my doc content in, it loses context between sessions, and I can't keep track of what I've asked before. But at least I can *ask it a question* and get an answer. "Find the stat about coaching effectiveness in my workshop notes" -- ChatGPT does that. This panel doesn't.

The other breaking point: portrait mode on my iPad. If viewing a source means I lose my editor entirely, and I have to tap back and forth constantly, that's actually *worse* than having two Safari tabs side by side in Split View. At least with Split View, I can see both at once.

---

### Marcus Chen's Reactions

**1. "If I opened DraftCrane and saw this, what would I think it does?"**

Three-column layout. Chapter navigation on the left with word counts -- nice, I can see my progress at a glance. Editor in the middle. Sources panel on the right with search and add. This is structured. I get it immediately.

My concern isn't understanding it -- it's scale. I have 12 subfolders in Google Drive with 3 to 15 documents each. That's potentially 80-100 source documents. This panel shows a flat list. Where's my folder structure? Where's the organizational hierarchy I spent weeks building in Drive?

I'd see four documents in the panel and think, "Okay, where are the rest?" Then I'd hit "Add" and start browsing my Drive through DraftCrane's file picker. But once I add them, they all land in a flat list. My "Interviews" subfolder and my "Frameworks" subfolder and my "Case Studies" subfolder -- all merged into one alphabetical list. That undoes the organizational work I've already done.

The search box mitigates this somewhat. If I can search by document name, I can find things fast. But browsing -- just looking at what I have, reminding myself of the landscape -- becomes harder, not easier.

**2. "Can I figure out how to find something in my research materials without instructions?"**

I'd use the search box. I'm comfortable with search. I'd type "coaching ROI" or "managers coaching stats" and expect results.

If search works across document content (not just titles), I'd find it quickly. My documents have reasonably descriptive content even if the titles aren't always helpful. I'd tap the result, read the relevant section, and go back.

If search is title-only, I'd mentally map the stat to the right subfolder in my head -- "that was from the Deloitte report, which is in my External Research folder" -- then scan the flat list for "Deloitte" something. I'd find it because I remember my own organizational system. But the flat list makes this slower than navigating my Drive folder structure directly.

The real problem is when I'm not sure which document has the information. With 80+ sources in a flat list, I can't just scan. I need either good search or some organizational structure within DraftCrane.

**3. "If I'm writing Chapter 4 and need to check a fact from an old workshop doc, what do I do?"**

I look at the Sources panel. In landscape on my iPad Air, I can see it alongside the editor. Good. I tap the document I think has the stat. The detail view replaces the list. I scroll through it.

This is... workable. Not great, but workable. The document is right there. I can read it. I can see my editor has been pushed to the left but is still partially visible (in landscape, at least). I find the stat, confirm it's 67%, go back to the list, and get back to writing.

The friction is manageable for me because I'm organized. I usually know which document to look in. But I'd want a way to jump back to exactly where I was in the source viewer if I need to check a second fact from the same document. If tapping "Back" loses my scroll position and I have to re-find my place, that's irritating.

**4. "Does this feel like one more thing to learn, or like it's helping me?"**

It feels like a minor improvement. I currently use a system of subfolders and a master index Google Sheet to track which documents go with which chapters. This replaces the "open in another tab" part of my workflow, which saves time. But it doesn't replace my index sheet. It doesn't help me see the relationship between sources and chapters.

The removal of chapter linking actually concerns me. I *want* to associate specific sources with specific chapters. That's how I organize my thinking. In the current design, the "link" feature was confusing (I'll grant that), but the underlying need -- "Chapter 4 draws from these 5 documents, Chapter 7 draws from these 3" -- is real. Flattening everything to one project-level list loses that structure.

I'd use this, but I'd probably also keep my Google Sheet index alongside it. Which means DraftCrane isn't fully replacing my existing system -- it's just adding a slightly better file viewer.

**5. "What would make me go back to copy-pasting between Google Docs and ChatGPT?"**

If I can't organize my sources at all -- no folders, no tags, no chapter associations -- I'll revert to my Drive folder system within a month. The flat list doesn't scale for my project. I have 12 chapters planned and 100+ documents. I need to be able to filter, group, or at minimum tag my sources.

The other deal-breaker: if adding sources from Drive is a pain. I have deep folder structures. If the inline Drive browser requires 8 taps to reach a document in my "Interviews / Executive Coaching / 2024" subfolder, and I have to do that 50 times to populate my source library, I'll give up after the third document and just keep using Drive directly.

---

## Option B: "Research Companion"

### Diane Mercer's Reactions

**1. "If I opened DraftCrane and saw this, what would I think it does?"**

Three columns again, but the right panel says "Research" at the top with three tabs: Sources, Ask, Clips. Let me look at each.

"Sources" -- okay, same as before, that's my documents. "Ask" -- wait. Ask? Like... I can ask it questions? I'd tap on that tab out of curiosity. I see a text field that says "Ask about your sources..." Oh. *Oh.* Like ChatGPT, but it already knows my stuff? I wouldn't have to paste anything in?

That's the moment. That single text field would make me understand what this tool is for. It's not just a file organizer. It's a research assistant that can actually *look through* my documents and find things. I'd immediately type something: "What did I write about psychological safety?" And if it came back with an answer citing my workshop notes -- with the actual document name and a quote -- I would feel something I don't often feel with new software: genuine excitement.

"Clips" -- I'm not sure what that means at first. Clips of what? Video clips? I'd tap on it and see it's empty. "0 clips saved." Okay, I don't know what this is yet but I'll come back to it.

Two out of three tabs make immediate sense. That's a strong start.

**2. "Can I figure out how to find something in my research materials without instructions?"**

I'd go straight to the "Ask" tab. "Find the stat about managers who receive coaching." If the AI finds it and tells me "In your document 'Workshop Notes March 2024,' page 3: '67% of managers who receive structured coaching show measurable improvement in team outcomes within 6 months'" -- I would actually tear up a little. I've been looking for that number for three weeks across 30 documents.

The Sources tab also has search, so if I wanted to browse manually, I could. But why would I? The Ask tab is faster and smarter. It searches *inside* all my documents at once. That's the thing I couldn't do before.

Where I might get stuck: if the AI gives me a wrong answer or can't find it. "I couldn't find information about that in your sources." Then I'd have to fall back to the Sources tab and manually browse. But at least I have the fallback. I'm not worse off than Option A -- I just have an extra tool that might save me time.

**3. "If I'm writing Chapter 4 and need to check a fact from an old workshop doc, what do I do?"**

I tap the "Ask" tab (if I'm not already there) and type: "What's the stat about psychological safety and team performance?" The AI responds with the quote, the document name, and where in the document it found it.

I verify the number. I go back to my chapter and keep writing. Total interruption: maybe 20 seconds. My flow barely breaks.

And then -- *and then* -- I see the "Save to Clips" button on the AI's response. I tap it because why not. Now that quote is saved somewhere. Later, when I'm writing Chapter 7 and need the same stat, I go to the Clips tab and it's right there. I don't have to re-ask. I don't have to remember which chapter I was in when I found it.

That's when the "Clips" tab makes sense to me. It's my collection of useful quotes. Like sticky notes in a real book. I finally understand the three tabs: Sources is my bookshelf. Ask is my research assistant. Clips is my sticky notes. That metaphor clicks.

**4. "Does this feel like one more thing to learn, or like it's helping me?"**

This feels like it's helping me. Genuinely. The Ask tab alone is worth switching from my current Google Docs + ChatGPT setup. Right now, I open ChatGPT, paste in 2,000 words from one document, ask a question, get an answer, then realize the stat I need is in a *different* document, paste that one in, ask again... it's exhausting. This does all of that automatically because it already has my documents.

The three tabs are more to learn than Option A's single panel. But the tabs are labeled with normal words and each does one clear thing. I don't feel overwhelmed. I feel like I have tools I'll actually use. The Sources tab is there if I want to browse, but honestly, I think I'd live in the Ask tab.

The Clips tab is the one that might not stick immediately. Saving clips is an extra step in my workflow that I don't currently do. Right now I just copy-paste. But if the "Insert" button on a clip puts the quote into my chapter *and* adds a footnote automatically? That's worth the extra step. I hate doing footnotes manually.

**5. "What would make me go back to copy-pasting between Google Docs and ChatGPT?"**

If the AI gives bad answers. Full stop. If I ask "Find the coaching stat" and it says "I found a reference to coaching in your document" but gives me the wrong number, or cites the wrong document, or just makes something up -- I will never trust it again. And I'll go right back to ChatGPT, where at least I can paste in the exact document and know it's reading the right thing.

The second risk: if it's slow. ChatGPT responds in a few seconds. If the Ask tab takes 10 seconds to search my sources, I'll feel like I'm waiting instead of working. The whole point is that this is faster than my current method.

The third, smaller risk: if adding my documents to DraftCrane is complicated. If I have to connect my Google account, navigate through folders, select files one by one, wait for each to process... I'll do it for the first 5 documents and then decide the rest aren't worth the effort. Then the AI can only search 5 of my 30 documents, which makes it unreliable. Initial setup friction could undermine the whole thing.

---

### Marcus Chen's Reactions

**1. "If I opened DraftCrane and saw this, what would I think it does?"**

Research panel with three tabs. I see Sources, Ask, Clips. The Sources tab looks like a cleaned-up version of a file manager. The Ask tab is a chat interface for querying my documents. Clips is a snippet collection.

I immediately understand the architecture here: this is a unified research workspace. Sources are the raw materials. Ask is the query interface. Clips are the curated outputs. That's a pipeline: raw material goes in, useful excerpts come out. I like pipelines. This makes structural sense to me.

My first question is about the Ask tab's capabilities. Can I ask it to compare information across documents? "What do Document A and Document B say differently about leadership resilience?" If it can do that, this solves my core problem -- I have too many documents saying overlapping things, and I need to consolidate.

My second question: can I see which sources the AI is drawing from? In ChatGPT Projects, I sometimes get answers where I can't tell if the AI is using my documents or making things up. If the Ask tab shows me "Based on Interview-Smith.doc (p.3) and Q4-Report.doc (p.12)," with clickable links to those passages, that's significantly better than ChatGPT.

**2. "Can I figure out how to find something in my research materials without instructions?"**

Two paths available to me, and I'd use both depending on context.

If I know *which* document has the information -- say, I know the coaching stat is in my Deloitte report -- I'd go to the Sources tab, search for "Deloitte," open it, and find the stat manually. This is the direct path.

If I don't know which document has it, or if it might be in several documents, I'd go to the Ask tab. "Which of my documents discusses coaching ROI statistics?" The AI could tell me it's mentioned in three documents and give me the relevant passages from each. That's something I literally cannot do today without opening each document individually.

Where I'd want more: after the AI shows me the results, I'd want to tap on a citation and go directly to that spot in the source document. If "Interview-Smith.doc, p.3" is a link that opens the source viewer scrolled to page 3, that's seamless. If it's just text and I have to manually open the document and scroll, that breaks the efficiency gain.

**3. "If I'm writing Chapter 4 and need to check a fact from an old workshop doc, what do I do?"**

I'd use the Ask tab. "What's the psychological safety stat from the team effectiveness research?" The AI returns the answer with citations. I verify the number, see it matches my recollection, and keep writing.

But here's what I'd really want to do next: save that clip *tagged to Chapter 4*. When I'm later reviewing Chapter 4, I want to see all the clips I collected for it. The flat Clips tab is fine for now, but as my book grows and I have 50+ clips across 15 chapters, I'll need to filter by chapter.

The workflow for me would be: Ask a question, get a result, save it to Clips, tag it "Chapter 4," and then later when I'm editing Chapter 4, pull up all the Chapter 4 clips to make sure I've incorporated all my research. That's the organizational structure I need. The current Clips design doesn't show this level of organization, but the infrastructure seems like it could support it in a future iteration.

**4. "Does this feel like one more thing to learn, or like it's helping me?"**

This feels like it's solving the right problem. My problem isn't finding my files -- I know where they are. My problem is that I have *too many* files and I need help synthesizing across them. The Ask tab directly addresses that. "What have I collected about leadership resilience across all my documents?" -- that question currently takes me 90 minutes to answer by opening documents one at a time. If the AI can answer it in 10 seconds, this tool pays for itself in the first session.

The three-tab structure adds a small learning curve, but each tab maps to a distinct workflow I actually have: browse files (Sources), ask questions (Ask), collect useful bits (Clips). These aren't abstract concepts -- they're things I already do, just scattered across Google Drive, ChatGPT, and Apple Notes. Having them in one panel next to my editor is a real consolidation.

The only cognitive overhead I see is managing the Clips. When do I save a clip versus just remembering the information? How many clips is too many? Should I organize them? This is the kind of organizational anxiety that slows me down with any system. But at least the clips are optional -- I can use the Ask tab without ever saving anything.

**5. "What would make me go back to copy-pasting between Google Docs and ChatGPT?"**

If the AI can't handle the scale of my research. I have 100+ documents. If the Ask tab works great with 10 documents but gives vague, unreliable answers when I've loaded all 100, that's a fundamental failure. The whole point is that it handles scale I can't handle manually.

Second: if there's no way to organize clips by chapter as the collection grows. With 15 chapters and potentially 100+ clips, a flat list becomes as unusable as a flat source list. I need at least basic filtering.

Third: if the citation links are decorative rather than functional. If the AI says "according to Interview-Smith.doc" but I can't tap that to verify, I'll never fully trust the answers. And if I can't trust the answers, I'll go back to verifying manually -- which means I'm back to opening individual documents, which means DraftCrane is just a worse version of Google Drive.

---

## Option C: "Integrated Research Assistant"

### Diane Mercer's Reactions

**1. "If I opened DraftCrane and saw this, what would I think it does?"**

Okay, this is different. I see my chapters on the left, a big open editor in the middle, and... that's it. There's a "Research" button at the bottom right corner of the editor, but nothing else. The right side of the screen is just more editor space.

My first thought: "Wait, where are my documents? Where's my research?" I'd stare at this for a few seconds feeling like something is missing. In Options A and B, I could see my source files right away. Here, I see a blank writing space and one button.

I'd tap "Research." A panel slides in. And instead of showing me a list of files, it shows me... a text field. "Ask about your sources..." There's a small gear icon in the top right and a "Clips: 0" badge. That's it.

This is either brilliant or terrifying, and I'm not sure which. On one hand, it's radically simple. There's nothing to figure out -- just type a question. On the other hand, I feel disoriented. Where are my files? Did they get imported? Are they connected? The panel doesn't tell me. I have to trust that somewhere behind this text field, my documents are there and the AI knows about them.

I think I'd tap the gear icon out of anxiety. I'd see my connected sources listed there -- six documents. Okay, they're there. I can breathe. But I shouldn't *have* to check. The main interface should give me some confidence that my stuff is connected without making me look for it.

**2. "Can I figure out how to find something in my research materials without instructions?"**

The interface basically forces me to use the AI. There's no browse-first option visible. So I'd type: "Find the stat about managers who receive coaching."

If the AI nails it -- gives me the exact quote with the document name -- this is the fastest, most intuitive experience of all three options. I didn't have to browse. I didn't have to remember which file it was in. I just asked, like I would ask a research assistant.

But if the AI fumbles -- gives me a vague answer, cites the wrong document, or says "I couldn't find that" when I *know* it's in my notes -- I'm stuck. How do I search manually? I'd have to tap the gear icon, find the right document, tap "View," and then scroll through it. That's 3 taps just to get to the same starting point that Option A gives me for free.

There's a psychological issue here too. In Options A and B, I can *see* my documents. I feel in control. Here, I'm delegating control to the AI. That's fine when the AI is right. When it's wrong, I feel helpless. I'm the kind of person who wants to verify things myself. If the AI says "the stat is 67%," I want to open the document and see it with my own eyes. Option C makes that verification harder than it needs to be.

**3. "If I'm writing Chapter 4 and need to check a fact from an old workshop doc, what do I do?"**

I tap "Research" to open the panel (if it's not already open). I type my question. The AI responds. I verify the answer and keep writing.

In the happy path, this is the most seamless experience. Open panel, ask, get answer, close panel, keep writing. Three taps and a few seconds. My flow barely pauses.

But the unhappy path is worse than the other options. If the AI misunderstands my question, or gives me a result from the wrong document, I have to either rephrase and ask again (adding time and frustration), or bail out to the source settings to browse manually (which is buried behind the gear icon, behind a "View" button, and requires me to know which document to look in). The backup path has more friction than Option A's *primary* path.

And there's another scenario: what if I'm not looking for a specific fact? What if I want to re-read an entire section of my workshop notes to refresh my memory? "I want to read the part about team dynamics from my March notes." The AI would give me a summary or an excerpt. But I don't want a summary -- I want to read my own words. Getting to the full document view requires navigating through settings, which feels wrong. Reading my own source documents shouldn't feel like going into the settings menu.

**4. "Does this feel like one more thing to learn, or like it's helping me?"**

When it works, it feels like magic. It feels like having a human research assistant who's read all my notes. I ask, they answer, I write. That's the dream.

When it doesn't work -- when the AI is slow, or wrong, or I need to do something the AI can't do (like browse my documents) -- it feels like I'm fighting the tool. The AI is standing between me and my own files. I have to go through it to get to my stuff.

This is the most opinionated of the three designs. It has a strong opinion about how I should work: "Don't browse, ask." For someone like me, who's used to having my documents visible and accessible, that opinion might be wrong. I'm not an "ask questions" person yet -- I'm a "look through my stuff" person. Option C is trying to change my workflow, not accommodate it.

I could see myself growing into this over time. If the AI is consistently good, I'd eventually stop wanting to browse and start asking for everything. But there's a trust-building period, and during that period, I'd want the browsing to be easier than 2 taps into a settings submenu.

**5. "What would make me go back to copy-pasting between Google Docs and ChatGPT?"**

One bad AI answer. Honestly, one is probably enough in the first week. If I'm relying entirely on the AI to find things in my documents and it gets something wrong -- wrong stat, wrong document attribution, a hallucinated quote that sounds real but isn't in any of my docs -- I will immediately lose trust in the entire system.

With Options A and B, a bad AI answer isn't catastrophic because I have manual browsing as a primary feature. I can verify. I can look things up myself. With Option C, the AI *is* the product. If the AI fails, the product fails.

The second trigger: if initial setup is confusing. Option C buries source management in settings. If I connect my Google Drive and add some documents but can't see them prominently -- just a "6 sources connected" note at the bottom of the Research panel -- I won't feel confident that my sources are properly ingested. Did it actually read them? Does it understand them? I need some kind of confirmation that's more reassuring than a number at the bottom of a panel.

---

### Marcus Chen's Reactions

**1. "If I opened DraftCrane and saw this, what would I think it does?"**

Clean writing space. Chapters on the left, big editor in the middle. A "Research" button tucked in the corner. This is a writing-first design. The statement it makes is: "Your primary activity here is writing. Research is available when you need it."

I appreciate the philosophy but I'm suspicious of it. I *want* to see my research landscape. I want to know which sources are connected, how many there are, whether they've been updated since I last looked. Option C hides all of that behind a gear icon inside a panel I have to actively open. That's three levels deep from my default view.

When I open the Research panel, I see the conversational interface. No tabs. Just a text field and some response history. This is clearly modeled after ChatGPT, and I get it -- type a question, get an answer from my documents. But my relationship with my research isn't primarily conversational. I don't always have a question. Sometimes I want to survey the territory. "Let me look at my Chapter 5 sources and see what I have to work with." Option C doesn't support that workflow naturally.

The Clips badge and the gear icon are the secondary features. I understand what they do -- saved snippets and source management. But they feel like afterthoughts in this design, tucked into small UI elements. Clips especially feel like they deserve more prominence if they're supposed to be the bridge between research and writing.

**2. "Can I figure out how to find something in my research materials without instructions?"**

I'd type in the Ask field: "Which documents mention coaching ROI?" The AI would (hopefully) list the relevant documents with excerpts.

This actually works well for my use case -- I have too many documents to browse manually, so having AI search across all 100+ of them is genuinely useful. The conversational interface is the right tool for the "needle in a haystack" problem.

But I'd run into an issue with precision. I might ask "What data do I have on executive coaching effectiveness?" and get results that blend my interview notes with published research with my own draft content. I'd want to be able to say "Only search in documents from my External Research folder" or "Exclude my draft chapters." Without scoping controls, the AI is searching everything, and for someone with 100+ documents including drafts, notes, research, and outlines, "everything" is too broad.

The manual fallback (gear icon, source list, view) is fine but slow. For my "I know exactly which document I want" use case, it's 3 taps to start reading versus 1 tap in Option B. That matters when I'm in flow.

**3. "If I'm writing Chapter 4 and need to check a fact from an old workshop doc, what do I do?"**

I open the Research panel and ask. The AI gives me an answer with a citation. I check the citation, verify it, and keep writing.

For fact-checking, this is the optimal flow. I'm not the person who needs to see the full source document to verify a number -- I trust the citation if it shows me the exact passage and tells me where it came from. So for quick fact-checks, Option C is the fastest of the three.

But there's a different scenario that concerns me more: "I'm writing Chapter 4 and I want to review the source material I haven't used yet, to see if there's anything I'm missing." This is a browsing task, not a question-answering task. I don't have a specific query -- I want to survey. Option C makes surveying my unused sources difficult. I'd have to go to settings, scan the source list, open documents one by one, and manually track what I've used versus what I haven't. None of that is supported by the AI-first paradigm.

**4. "Does this feel like one more thing to learn, or like it's helping me?"**

For the question-answering workflow, this is the most helpful option. No question. The AI searching across 100+ documents and giving me cited answers is the capability I need most. If I could only choose one feature, it would be this.

But the rest of my workflow -- organizing, surveying, planning which sources go with which chapters, tracking what I've used -- gets worse. Option C took the thing I'm good at (organizing) and said "you don't need to do that anymore." But I do. Organization isn't overhead for me; it's how I think. Removing my ability to browse, sort, and associate sources by chapter doesn't free me -- it constrains me.

The trade-off is clear: Option C is the best tool for "finding" and the worst tool for "organizing." Since I need both, this design serves only half my workflow.

**5. "What would make me go back to copy-pasting between Google Docs and ChatGPT?"**

If I can't browse and organize my sources effectively. The gear icon is not an organizational interface -- it's a flat list with "View" and "Remove" buttons. No folders, no tags, no chapter associations, no metadata about when I last accessed a source or whether its content has been used in a chapter. For someone managing a 15-chapter book with 100+ source documents, this is like managing a library with a single shelf and no catalog.

Also: if the AI responses are too slow for the conversational back-and-forth that Option C depends on. In ChatGPT, I've internalized a 3-5 second response time. If DraftCrane's AI takes 10+ seconds because it's searching across many documents on Cloudflare Workers, the conversational flow breaks and I'm just staring at a loading spinner. At that point, I'd rather have a source list I can browse immediately.

The biggest strategic risk for me: Option C is an all-or-nothing bet on AI. If the AI is excellent, it's the best option. If the AI is mediocre -- and realistically, AI searching across 100+ heterogeneous Google Docs of varying formats, lengths, and topics will have quality issues -- then I've given up manual tools (demoted to settings) in exchange for an unreliable AI, and I've lost both ways.

---

## Verdicts

### Diane's Pick

Option B. Here's why.

I came into this expecting to love Option C -- the "just ask" model sounded like exactly what I need. And it is, in the happy path. But I know myself. I'm the person who will not trust the AI fully on day one. I need to be able to check its work. I need to see my documents with my own eyes sometimes. Option C makes that hard. It's like hiring a research assistant but then locking the filing cabinet.

Option B gives me the AI I want (the Ask tab) *and* the filing cabinet I need (the Sources tab). When the AI gives me an answer, I can tap through to the source document and verify it myself. When I don't have a specific question, I can browse my files. When I find something useful, I can save it to Clips and insert it later with a proper footnote.

Option A is fine but boring. It's a file browser. I already have a file browser. I didn't switch to DraftCrane for a slightly better file browser.

Option B respects that I'm still learning to trust AI with my own material. It gives me the power tools without taking away the hand tools. That's what I need right now.

### Marcus's Pick

Option B, but with a strong asterisk.

Option B is the right architecture. Three tabs: browse, ask, collect. That maps to my actual workflow: survey my research, query across documents, gather what I need. The Sources tab gives me direct access. The Ask tab gives me AI search across 100+ documents. The Clips tab gives me a staging area between research and manuscript.

My asterisk: the flat source list and the flat clips list won't scale for my project. I need at least basic filtering -- by chapter tag, by document type, by "used/unused" status. Option B as designed is a strong start, but without organizational features in the Sources and Clips tabs, I'll outgrow it by Chapter 6.

I rejected Option A because it doesn't include AI search, and AI search is the feature that solves my core problem of having too many documents to manage manually. I rejected Option C because it demotes source browsing to a settings submenu, and I need browsing to be a first-class activity. I'm an organizer. Taking away my ability to see, sort, and structure my sources is taking away how I think.

Option B is the one that respects both my need for AI power *and* my need for structural organization. It treats sources, querying, and collection as equally important activities. That's correct.

### Consensus and Conflicts

**Where the personas agree:**

1. Both choose Option B. The three-tab model (Sources, Ask, Clips) maps to a workflow both personas actually have, even though they arrive at it differently -- Diane through frustration with finding things, Marcus through frustration with organizing things.

2. Both value the AI query feature (Ask tab) as the primary differentiator from their current workflow. Neither persona is excited about a better file browser alone (Option A). Both see "ask a question about my documents" as the breakthrough capability.

3. Both are suspicious of Option C's all-in bet on AI. Neither persona fully trusts AI with their own material yet. Both want the ability to manually browse and verify. Option C's demotion of source browsing to a settings submenu makes both personas uncomfortable, though for different reasons (Diane fears loss of control; Marcus fears loss of organizational visibility).

4. Both identify the same failure mode: bad AI answers are the death of the product. If the AI misattributes, hallucinates, or fails to find information that clearly exists in the sources, both personas will abandon DraftCrane and return to their current (painful but familiar) workflows.

**Where the personas conflict:**

1. **Source organization.** Diane doesn't care about organizing sources -- she just wants to find things. Marcus needs folders, tags, or chapter associations to manage 100+ documents. Option B as designed serves Diane well (flat list + search + AI is enough for 30 documents) but will frustrate Marcus as his library grows. The design must plan for organizational features (even if they ship later) without cluttering Diane's simpler experience.

2. **Browsing vs. asking.** Diane would live primarily in the Ask tab and rarely browse Sources manually. Marcus would split his time roughly evenly between Sources and Ask, using browsing for survey and planning, and asking for needle-in-haystack queries. Option B's equal treatment of all three tabs accommodates both, but the default tab may need to be personalized (Diane defaults to Ask, Marcus defaults to Sources) or the design needs to be neutral enough that both feel at home.

3. **Clips complexity tolerance.** Diane wants Clips to be dead simple: save a quote, insert it later, done. Marcus wants Clips to be organizable: tag by chapter, filter, sort, track which clips have been inserted. These are fundamentally different views of the same feature. The design must start simple (Diane's version) with organizational features available but not required (Marcus's version).

**What this tells us about the design:**

The strongest signal from both personas is that Option B's architecture is right, but the execution must thread a needle between Diane's simplicity needs and Marcus's organizational needs. The three-tab model is the correct skeleton. The work ahead is:

- Making the Sources tab scale from 10 documents (Diane) to 100+ documents (Marcus) without becoming overwhelming at either end.
- Ensuring the Ask tab's AI quality is high enough to justify the product's existence. Both personas identified AI quality as the single biggest risk.
- Building Clips as a simple save-and-insert feature first (for Diane), with chapter tagging and filtering as a fast follow (for Marcus).
- Making the initial source-adding experience frictionless enough that both personas will add their complete document libraries, not just the first 5 files.

Option B also carries a strategic advantage: it can be shipped incrementally. The Sources tab can ship first (essentially Option A within the new panel structure), then the Ask tab adds AI capability, then the Clips tab completes the pipeline. Each increment delivers standalone value. Option C cannot be shipped incrementally -- without AI, it's an empty panel. This phasing aligns with both personas' need to build trust over time rather than placing a single large bet on AI quality at launch.
